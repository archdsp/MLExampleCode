{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <th>...</th>\n",
       "      <th>nose_tip_y</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.033564</td>\n",
       "      <td>39.002274</td>\n",
       "      <td>30.227008</td>\n",
       "      <td>36.421678</td>\n",
       "      <td>59.582075</td>\n",
       "      <td>39.647423</td>\n",
       "      <td>73.130346</td>\n",
       "      <td>39.969997</td>\n",
       "      <td>36.356571</td>\n",
       "      <td>37.389402</td>\n",
       "      <td>...</td>\n",
       "      <td>57.066803</td>\n",
       "      <td>61.195308</td>\n",
       "      <td>79.970165</td>\n",
       "      <td>28.614496</td>\n",
       "      <td>77.388992</td>\n",
       "      <td>43.312602</td>\n",
       "      <td>72.935459</td>\n",
       "      <td>43.130707</td>\n",
       "      <td>84.485774</td>\n",
       "      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.332936</td>\n",
       "      <td>34.970077</td>\n",
       "      <td>29.949277</td>\n",
       "      <td>33.448715</td>\n",
       "      <td>58.856170</td>\n",
       "      <td>35.274349</td>\n",
       "      <td>70.722723</td>\n",
       "      <td>36.187166</td>\n",
       "      <td>36.034723</td>\n",
       "      <td>34.361532</td>\n",
       "      <td>...</td>\n",
       "      <td>55.660936</td>\n",
       "      <td>56.421447</td>\n",
       "      <td>76.352000</td>\n",
       "      <td>35.122383</td>\n",
       "      <td>76.047660</td>\n",
       "      <td>46.684596</td>\n",
       "      <td>70.266553</td>\n",
       "      <td>45.467915</td>\n",
       "      <td>85.480170</td>\n",
       "      <td>219 215 204 196 204 211 212 200 180 168 178 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.057053</td>\n",
       "      <td>34.909642</td>\n",
       "      <td>30.903789</td>\n",
       "      <td>34.909642</td>\n",
       "      <td>59.412000</td>\n",
       "      <td>36.320968</td>\n",
       "      <td>70.984421</td>\n",
       "      <td>36.320968</td>\n",
       "      <td>37.678105</td>\n",
       "      <td>36.320968</td>\n",
       "      <td>...</td>\n",
       "      <td>53.538947</td>\n",
       "      <td>60.822947</td>\n",
       "      <td>73.014316</td>\n",
       "      <td>33.726316</td>\n",
       "      <td>72.732000</td>\n",
       "      <td>47.274947</td>\n",
       "      <td>70.191789</td>\n",
       "      <td>47.274947</td>\n",
       "      <td>78.659368</td>\n",
       "      <td>144 142 159 180 188 188 184 180 167 132 84 59 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.225739</td>\n",
       "      <td>37.261774</td>\n",
       "      <td>32.023096</td>\n",
       "      <td>37.261774</td>\n",
       "      <td>60.003339</td>\n",
       "      <td>39.127179</td>\n",
       "      <td>72.314713</td>\n",
       "      <td>38.380967</td>\n",
       "      <td>37.618643</td>\n",
       "      <td>38.754115</td>\n",
       "      <td>...</td>\n",
       "      <td>54.166539</td>\n",
       "      <td>65.598887</td>\n",
       "      <td>72.703722</td>\n",
       "      <td>37.245496</td>\n",
       "      <td>74.195478</td>\n",
       "      <td>50.303165</td>\n",
       "      <td>70.091687</td>\n",
       "      <td>51.561183</td>\n",
       "      <td>78.268383</td>\n",
       "      <td>193 192 193 194 194 194 193 192 168 111 50 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.725301</td>\n",
       "      <td>39.621261</td>\n",
       "      <td>32.244810</td>\n",
       "      <td>38.042032</td>\n",
       "      <td>58.565890</td>\n",
       "      <td>39.621261</td>\n",
       "      <td>72.515926</td>\n",
       "      <td>39.884466</td>\n",
       "      <td>36.982380</td>\n",
       "      <td>39.094852</td>\n",
       "      <td>...</td>\n",
       "      <td>64.889521</td>\n",
       "      <td>60.671411</td>\n",
       "      <td>77.523239</td>\n",
       "      <td>31.191755</td>\n",
       "      <td>76.997301</td>\n",
       "      <td>44.962748</td>\n",
       "      <td>73.707387</td>\n",
       "      <td>44.227141</td>\n",
       "      <td>86.871166</td>\n",
       "      <td>147 148 160 196 215 214 216 217 219 220 206 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0          66.033564          39.002274           30.227008   \n",
       "1          64.332936          34.970077           29.949277   \n",
       "2          65.057053          34.909642           30.903789   \n",
       "3          65.225739          37.261774           32.023096   \n",
       "4          66.725301          39.621261           32.244810   \n",
       "\n",
       "   right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0           36.421678                59.582075                39.647423   \n",
       "1           33.448715                58.856170                35.274349   \n",
       "2           34.909642                59.412000                36.320968   \n",
       "3           37.261774                60.003339                39.127179   \n",
       "4           38.042032                58.565890                39.621261   \n",
       "\n",
       "   left_eye_outer_corner_x  left_eye_outer_corner_y  right_eye_inner_corner_x  \\\n",
       "0                73.130346                39.969997                 36.356571   \n",
       "1                70.722723                36.187166                 36.034723   \n",
       "2                70.984421                36.320968                 37.678105   \n",
       "3                72.314713                38.380967                 37.618643   \n",
       "4                72.515926                39.884466                 36.982380   \n",
       "\n",
       "   right_eye_inner_corner_y  ...  nose_tip_y  mouth_left_corner_x  \\\n",
       "0                 37.389402  ...   57.066803            61.195308   \n",
       "1                 34.361532  ...   55.660936            56.421447   \n",
       "2                 36.320968  ...   53.538947            60.822947   \n",
       "3                 38.754115  ...   54.166539            65.598887   \n",
       "4                 39.094852  ...   64.889521            60.671411   \n",
       "\n",
       "   mouth_left_corner_y  mouth_right_corner_x  mouth_right_corner_y  \\\n",
       "0            79.970165             28.614496             77.388992   \n",
       "1            76.352000             35.122383             76.047660   \n",
       "2            73.014316             33.726316             72.732000   \n",
       "3            72.703722             37.245496             74.195478   \n",
       "4            77.523239             31.191755             76.997301   \n",
       "\n",
       "   mouth_center_top_lip_x  mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "0               43.312602               72.935459                  43.130707   \n",
       "1               46.684596               70.266553                  45.467915   \n",
       "2               47.274947               70.191789                  47.274947   \n",
       "3               50.303165               70.091687                  51.561183   \n",
       "4               44.962748               73.707387                  44.227141   \n",
       "\n",
       "   mouth_center_bottom_lip_y  \\\n",
       "0                  84.485774   \n",
       "1                  85.480170   \n",
       "2                  78.659368   \n",
       "3                  78.268383   \n",
       "4                  86.871166   \n",
       "\n",
       "                                               Image  \n",
       "0  238 236 237 238 240 240 239 241 241 243 240 23...  \n",
       "1  219 215 204 196 204 211 212 200 180 168 178 19...  \n",
       "2  144 142 159 180 188 188 184 180 167 132 84 59 ...  \n",
       "3  193 192 193 194 194 194 193 192 168 111 50 12 ...  \n",
       "4  147 148 160 196 215 214 216 217 219 220 206 18...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/face-landmark/training.csv\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape : (2140, 31)\n",
      "Image data len : 2140\n",
      "Image data [0].shape : (9216,)\n"
     ]
    }
   ],
   "source": [
    "# 결측치가 있는 row를 삭제\n",
    "data = data.dropna()\n",
    "\n",
    "# 이미지 데이터가 ndarray가 아니면 읽어서 ndarray로 처리합니다.\n",
    "if not isinstance(data['Image'][0], np.ndarray):\n",
    "    data['Image'] = data['Image'].apply(lambda row: np.fromstring(row, sep=' '))\n",
    "\n",
    "# (2140, 31)\n",
    "#   31 : 가로, 데이터 종류\n",
    "# 2140 : 세로, 데이터 개수 (원래 7049 였는데 결측치 제거로 2140개만 남음)\n",
    "print(f\"data.shape : {data.shape}\")\n",
    "\n",
    "# 데이터 이미지 개수 2140개\n",
    "print(f\"Image data len : {len(data['Image'])}\")\n",
    "\n",
    "# 데이터 이미지의 shape은 9216=(=96*96)\n",
    "print(f\"Image data [0].shape : {data['Image'][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 9216)\n",
      "image count : 2140\n",
      "(2140, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터만 갖고 와서 쌓기\n",
    "X_train = np.vstack(data['Image'].values)\n",
    "# (2140, 9216) = 9216(96 * 96) 픽셀의 이미지가 2140개 있음\n",
    "print(X_train.shape)\n",
    "\n",
    "# 기존 이미지 픽셀 범위 0 ~ 255를 0 ~ 1 으로 정규화\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "# 계산이 용이하도록 int로 표현되는 명암을 float 타입으로 변경\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "# 이미지 개수 : 2140\n",
    "print(f\"image count : {len(data['Image'].values)}\")\n",
    "\n",
    "# (96, 96) 2차원 이미지로 만들기\n",
    "X_train = X_train.reshape(-1, 96, 96, 1)\n",
    "\n",
    "# (96 * 96) 픽셀의 이미지 2140개\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape : (2140, 30)\n",
      "[[ 0.34357226 -0.23578708 -0.27903485 ...  0.414966    0.08298607\n",
      "   0.48534387]\n",
      " [ 0.42022967 -0.22094737 -0.4008804  ...  0.5402967  -0.06302392\n",
      "   0.8482105 ]\n",
      " [ 0.3577143  -0.2673     -0.5224184  ...  0.6037143  -0.05271428\n",
      "   0.8362857 ]\n",
      " ...\n",
      " [ 0.44972184 -0.27323046 -0.3730596  ...  0.4548477   0.02353642\n",
      "   0.8040795 ]\n",
      " [ 0.43840352 -0.15370175 -0.4083684  ...  0.5440877  -0.03985965\n",
      "   0.9047544 ]\n",
      " [ 0.35671037 -0.24173875 -0.353318   ...  0.5006386   0.09077578\n",
      "   0.6003548 ]]\n"
     ]
    }
   ],
   "source": [
    "# 맨 뒤에 있는 이미지 빼고 선택 -> Y\n",
    "Y_train = data[data.columns[:-1]].values\n",
    "print(f\"y.shape : {Y_train.shape}\")\n",
    "\n",
    "# 원래 0 ~ 96 이던 좌표를 변환 함\n",
    "# 이미지의 중앙점을 기준으로 -1 ~ 1 사이로 표현 되도록 처리\n",
    "Y_train = (Y_train - 48) / 48\n",
    "\n",
    " # shuffle train data\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=0)\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (maxpool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=30, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, padding=0)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpool2d = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=0)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=0)\n",
    "        self.conv4 = torch.nn.Conv2d(128, 256, kernel_size=3, padding=0)\n",
    "        self.conv5 = torch.nn.Conv2d(256, 512, kernel_size=3, padding=0)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "\n",
    "        self.fc1 = None\n",
    "        self.fc2 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc3 = torch.nn.Linear(1024, 512)\n",
    "        self.fc4 = torch.nn.Linear(512, 30)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "\n",
    "        x = self.conv2 (x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2d(x)\n",
    "\n",
    "        x =self.flatten(x)\n",
    "\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = torch.nn.Linear(x.shape[1], 2048)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2140, 1, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 1. NumPy 배열을 PyTorch Tensor로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "# 2. 차원 순서 변경: (batch_size, height, width, channels) -> (batch_size, channels, height, width)\n",
    "X_train = X_train.permute(0,  3, 2, 1 )\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# TensorDataset을 사용해 X_train과 Y_train 묶음\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "# DataLoader로 묶음(batch) 단위로 불러오기\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0261\n",
      "Epoch [2/10], Loss: 0.0054\n",
      "Epoch [3/10], Loss: 0.0053\n",
      "Epoch [4/10], Loss: 0.0051\n",
      "Epoch [5/10], Loss: 0.0052\n",
      "Epoch [6/10], Loss: 0.0049\n",
      "Epoch [7/10], Loss: 0.0047\n",
      "Epoch [8/10], Loss: 0.0046\n",
      "Epoch [9/10], Loss: 0.0042\n",
      "Epoch [10/10], Loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model.train()\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 학습 파라미터 설정\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Optimizer 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 배치 손실 누적\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 에포크 후 손실 출력\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 96, 96])\n",
      "(1, 30)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[1;32m     15\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m keypoints[\u001b[38;5;241m0\u001b[39m, i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m], keypoints[\u001b[38;5;241m0\u001b[39m, i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLINE_AA\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"test2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "img.resize((96, 96))\n",
    "img_tensor = torch.Tensor(img)\n",
    "img_tensor = img_tensor.reshape((1, 1, 96, 96))\n",
    "print(img_tensor.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predict = model(img_tensor)\n",
    "    keypoints = predict.numpy()\n",
    "    keypoints = keypoints * 48 + 48\n",
    "    print(keypoints.shape)\n",
    "    for i in range(15):\n",
    "        x, y = keypoints[0, i * 2], keypoints[0, i * 2 + 1]\n",
    "        cv2.circle(img, (x, y), 3, (255, 0, 0), 5, cv2.LINE_AA )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
