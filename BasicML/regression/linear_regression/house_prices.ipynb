{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 집 값 예측하기 실습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/house_price-train.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비 수치형 데이터를 인코딩하여 수치형으로 바꿔줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = data.select_dtypes(exclude=np.number).columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in non_numeric_columns:\n",
    "    data[i] = label_encoder.fit_transform(data[i])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수치형 데이터를 정규화 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "numeric_columns = data.select_dtypes(['int64', 'float64']).columns\n",
    "data[numeric_columns] = min_max_scaler.fit_transform(data[numeric_columns])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수들간의 상관관계를 분석합니다.\n",
    "독립변수들간에 상관관계가 높으면 중복해서 입력하는 효과가 있기 때문에 데이터를 사용하기 전에 데이터가 정규분포를 따르는지와 더붙어 상관관게 분석을 통해 같이 쓰지 말아야 할 독립 변수들을 파악하고 있는 것이 좋습니다.\n",
    "아래 코드는 우리가 예측하고자 하는 종속변수인 집값과의 상관계수를 구한 것으로써 이 경우에는 사실 경우에 따라 포함하여야 할지 특정 변수를 뺴야할지 달라질 수 있습니다. 너무 대부분의 독립변수들이 높은 상관관계를 가지게 되면 정답을 뻔하게 알게되고 데이터간 새로운 패턴이나 유의미함을 알 수 없기 떄문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(data[numeric_columns].corr().loc[:,\"SalePrice\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 중에 입력되지 않은 값이나 Nan값이 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "직접 Nan이나 빈값, inf값 등등 값들을 포함하는 레코드를 지워도 되지만, 이 예제에서는 빠른 실행을 위해 통째로 특정 컬럼을  제외하고 학습 데이터로 집어 넣겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data.loc[:, ~data.columns.isin(['LotFrontage', 'GarageYrBlt', 'MasVnrArea'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_train = data_filtered.to_numpy(dtype=np.float32)[:1000, :-1]\n",
    "y_train = data_filtered.to_numpy(dtype=np.float32)[:1000, -1]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_test \u001b[39m=\u001b[39m data_filtered\u001b[39m.\u001b[39mto_numpy(dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)[\u001b[39m1000\u001b[39m:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m y_test \u001b[39m=\u001b[39m data_filtered\u001b[39m.\u001b[39mto_numpy(dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)[\u001b[39m1000\u001b[39m:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m      4\u001b[0m y_predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "x_test = data_filtered.to_numpy(dtype=np.float32)[1000:, :-1]\n",
    "y_test = data_filtered.to_numpy(dtype=np.float32)[1000:, -1, np.newaxis]\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "score = model.score(x_test, y_test)\n",
    "print(f\"score = {score}\")\n",
    "\n",
    "plt.scatter(y_predict, y_test, c='b') # bwr : 파랑-흰색-빨강 색상맵"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2402d20b18b5ecc8b646c67fbbdeff4ca6ac76bfb47beb09a3e0912bc3b9212b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
