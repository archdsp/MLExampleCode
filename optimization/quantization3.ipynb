{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 양자화 - 오퍼레이터 합치기\n",
    "🔍 왜 오퍼레이터를 합치나요?\n",
    "\n",
    "1. 양자화된 연산은 정밀도가 낮아서 연산 분리 시 오류 누적이 크기 때문  \n",
    "* int8 연산은 float32보다 표현력이 적음 → 중간 결과 저장이 부정확해짐\n",
    "* 연산을 나눠두면 중간값이 더 많이 깨지고 정확도 손실이 큼\n",
    "\n",
    "-> 합치면 중간 결과 없이 한 번에 연산하므로 정확도 손실을 줄일 수 있음\n",
    "\n",
    "2. 실제 하드웨어에서는 분리된 연산보다 fused 연산이 훨씬 빠름  \n",
    "* 많은 양자화 하드웨어/엔진은 Conv+ReLU 또는 Conv+BN+ReLU를 하나의 커널로 실행함\n",
    "* 분리된 연산보다 메모리 접근 횟수가 줄어들고, 캐시 효율도 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization as quant\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 16, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "model = Model()\n",
    "\n",
    "# 오퍼레이터 합치기 수행\n",
    "model_fused = torch.quantization.fuse_modules(model, [['conv', 'relu']], inplace=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
