{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 네트워크란\n",
    "적대적 생성 신경망이라는 뜻으로 가짜 데이터를 생성하는 모델입니다. 이 이름이 붙여진 이유는 두 모델이 서로 적대적으로 학습되기 때문입니다. 네트워크 중 하나인 판별모델 Discriminator는 표본이 가짜 표본에 속하는지 진짜 표본에 속하는 지를 결정합니다. 반면 생성모델 Generator는 실제 데이터의 분포에 가깝도록 데이터를 만들어내게끔 학습됩니다. 원 논문에서는 이를 경찰과 위조 지폐범에 비유합니다. 생성모델은 위조 지폐를 만들어내어야 하는 위조범이 되고 판별 모델은 위조 지폐범에게 위조지폐를 받아 위조 지폐를 탐지 해내는 역할로 적대적인 관계를 갖게 됩니다. 이 경쟁은 위조지폐인지 아닌지 판단하기 어려울 때까지 지속됩니다.\n",
    "![](https://www.researchgate.net/publication/351558593/figure/fig1/AS:1023239748845568@1620970775250/A-standard-GAN-architecture-and-loss-function.png)\n",
    "## Loss 함수\n",
    "원본 데이터 분포에서 샘플 x를 뽑아 logD(x)의 기댓값 계산합니다.\n",
    "D(x)의 출력은 0~1사이의 확률로 1에 가까울 수록 진짜에 가깝다고 할 수 있습니다\n",
    "$$\n",
    "E_{x\\char`\\~p_{data(x)}}[logD(x)]\n",
    "$$\n",
    "\n",
    "노이즈를 하나 샘플링해서 가짜 이미지를 만든 다음에 $G(z)$에 판별자에 넣으면($D((G(z)))$) 가짜 이미지가 진짜인지\n",
    "아닌지에 대한 확률이 나오게됩니다. 1.0에서 해당 확률을 빼주게 되면 가짜 이미지가 들어왔을 경우 제대로 판별했다면 식의 값이\n",
    "0이 됩니다.\n",
    "$$\n",
    "E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))]\n",
    "$$\n",
    "\n",
    "전체 식이 아래와 같을 때 \n",
    "$$\n",
    "\\underset{G}{Min}\\underset{D}{Max} V(D, G) = E_{x\\char`\\~p_{data(x)}}[logD(x)] + E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))]\n",
    "$$\n",
    "\n",
    "### 판별자 D의 입장\n",
    "$x$는 실제 데이터 샘플이라 할 때 $z$는 잠재 공간의 무작위 샘플입니다. 판별자는 $D(x) = 1$, 생성된 데이터에 대해 $D(G(z))$ = 0 이 되록 학습합니다.\n",
    "$$\n",
    "\\underset{D}{Max} = E_{x\\char`\\~p_{data}(x)}[logD(x)] + E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))]\n",
    "$$0\n",
    "\n",
    "### 생성자 G의 입장\n",
    "반면에 생성자는 판별자와 반대로 아래 수식이 즉 판별자의 손실값이 최소가 되게끔 학습을 하려고 합니다.\n",
    "$$\n",
    "\\underset{G}{Min} = E_{x\\char`\\~p_{data}(x)}[logD(x)] + E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))]\n",
    "$$\n",
    "생성자에서 D(x)는 등장하지 않으니 정확히는 아래 수식을 최소화(0에 가깝게) 되도록 학습을 합니다. 판별자를 속여야하므로 생성된\n",
    "이미지가 진짜같아야 하니, 판별자의 손실이 최소화 되어야 하는 것 입니다.\n",
    "$$\n",
    "\\underset{G}{Min} = E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수식 증명\n",
    "먼저 Generator G를 고정 시키면 위 수식을 아래와 같이 쓸 수 있게 됩니다.\n",
    "아래 수식을 기댓값을 적분 형태로 나타낸 뒤, g(z)가 x로 매핑되는 과정이므로 하나의 적분에 합쳐 쓸 수 있게 됩니다.\n",
    "$$\n",
    "V(G,D) = \\underset{G}{Min}\\underset{D}{Max} V(D, G) = E_{x\\char`\\~p_{data(x)}}[logD(x)] + E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))] \\\\\n",
    "= \\int_{x}p_{data}(x)log(D(x))dx + \\int_{z}p_{z}(z)log(1 - D(g(z)))dz \\\\\n",
    "= \\int_{x}p_{data}(x)log(D(x)) + p_{x}(x)log(1 - D(x))dx\n",
    "$$\n",
    "\n",
    "$y = alog(y) + blog(1-y) $ 형태일 때 [0, 1] 사이에서 $\\frac{a}{a+b}$값이 최대값을 가지므로 G가 고정되었을 때 위 적분식은\n",
    "아래 수식에서 최댓값을 가지게 됩니다\n",
    "$$\n",
    "D_{G}(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_{g}(x)} \n",
    "$$\n",
    "\n",
    "그럼 G가 고정되었을 때 최대 D(x)의 최대값을 알았으니\n",
    "$$\n",
    "V(G,D) = \\underset{D}{Max} V(D, G) = E_{x\\char`\\~p_{data(x)}}[logD(x)] + E_{z \\char`\\~ p_{z}(z)}[log(1 - D(G(z)))] \\\\\n",
    "= E_{x\\char`\\~p_{data(x)}}[log\\frac{p_{data}(x)}{p_{data}(x) + p_{g}(x)}] + E_{z \\char`\\~ p_{z}(z)}[log\\frac{p_{g}(x)}{p_{data}(x) + p_{g}(x)})] \\\\\n",
    "= E_{x\\char`\\~p_{data(x)}}[log\\frac{2 * p_{data}(x)}{p_{data}(x) + p_{g}(x)}] + E_{z \\char`\\~ p_{z}(z)}[log\\frac{2 * p_{g}(x)}{p_{data}(x) + p_{g}(x)})] - log(4) \\\\\n",
    "= KL(p_{data} || \\frac{p_{data}(x) + p_{g}(x)}{2}) + KL(p_{g} || \\frac{p_{data}(x) + p_{g}(x)}{2}) - log(4) \\\\\n",
    "= 2 * JSD(p_{data} || p_{g}) - log(4)\n",
    "$$\n",
    "\n",
    "이렇게 나오게 된다. JSD는 data와 g의 분포가 동일할 때 0이 나오므로 학습이 잘 된다는 것은 Generator가 원본데이터와 동일한 데이터를 내뱉을 때 최적값을 갖게 됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 캐글 데이터 셋 준비\n",
    "https://www.kaggle.com/datasets/joosthazelzet/lego-brick-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 17:00:31.053051: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-25 17:00:31.177150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-25 17:00:31.234666: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-25 17:00:31.249766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-25 17:00:31.360718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 17:00:32.631591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers, Model, utils\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.pylab import plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729843240.622966  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843240.845811  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843240.845945  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843240.849345  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843240.849408  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843240.849423  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843242.733071  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729843242.733163  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-25 17:00:42.733176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729843242.733279  130640 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-25 17:00:42.733376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3323 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_data = utils.image_dataset_from_directory(\n",
    "    \"../dataset\",\n",
    "    labels = None,\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size=(64, 64),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    interpolation=\"bilinear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    tanh를 활성화 함수로 쓰기 위해 -1 ~ 1 사이로 조정해서 tanh 함수의 출력값과 범위를 맞춤\n",
    "    \"\"\"\n",
    "    img = (tf.cast(img, \"float32\") -127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = layers.Input(shape=(64, 64, 1))\n",
    "x = layers.Conv2D(64, 4, strides=2, padding=\"same\", use_bias=False)(discriminator_input)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(1, kernel_size=4, strides=1, padding=\"valid\", use_bias=False, activation=\"sigmoid\")(x)\n",
    "discriminator_output = layers.Flatten()(x)\n",
    "discriminator = Model(discriminator_input, discriminator_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = layers.Input(shape=(100,))\n",
    "x = layers.Reshape((1, 1, 100))(generator_input)\n",
    "x = layers.Conv2DTranspose(512, kernel_size=4, strides=1, padding=\"valid\", use_bias = False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "x = layers.LeakyReLU(0.2)(x)\n",
    "generator_output = layers.Conv2DTranspose(1, kernel_size=4, strides=2, padding=\"same\", use_bias=False, activation=\"tanh\")(x)\n",
    "generator = Model(generator_input, generator_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729843255.100653  131025 service.cc:146] XLA service 0x7f1b3c016690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729843255.100800  131025 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2024-10-25 17:00:55.285009: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-25 17:00:55.540404: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:61] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. random_uniform/RandomUniform\n",
      "2024-10-25 17:00:58.052753: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8902\n",
      "I0000 00:00:1729843271.874257  131025 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 91ms/step - d_loss: -2.7561 - g_loss: 5.5216\n",
      "Epoch 2/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: -3.1847 - g_loss: 5.6293\n",
      "Epoch 3/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.2380 - g_loss: 6.7544\n",
      "Epoch 4/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.1343 - g_loss: 6.3329\n",
      "Epoch 5/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -2.9876 - g_loss: 6.4529\n",
      "Epoch 6/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.3221 - g_loss: 6.6650\n",
      "Epoch 7/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -2.9999 - g_loss: 6.4531\n",
      "Epoch 8/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.3368 - g_loss: 6.5430\n",
      "Epoch 9/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.1553 - g_loss: 6.9195\n",
      "Epoch 10/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.3322 - g_loss: 6.9208\n",
      "Epoch 11/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -2.9435 - g_loss: 6.1535\n",
      "Epoch 12/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.3695 - g_loss: 7.1270\n",
      "Epoch 13/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.3962 - g_loss: 7.0278\n",
      "Epoch 14/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.4777 - g_loss: 7.1615\n",
      "Epoch 15/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.5441 - g_loss: 7.3091\n",
      "Epoch 16/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.1277 - g_loss: 6.9393\n",
      "Epoch 17/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.5448 - g_loss: 7.1027\n",
      "Epoch 18/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.4276 - g_loss: 7.2763\n",
      "Epoch 19/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - d_loss: -3.7064 - g_loss: 7.4941\n",
      "Epoch 20/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -3.8172 - g_loss: 7.8333\n",
      "Epoch 21/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.7879 - g_loss: 7.6207\n",
      "Epoch 22/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - d_loss: -4.0056 - g_loss: 8.1926\n",
      "Epoch 23/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -4.0692 - g_loss: 8.7168\n",
      "Epoch 24/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -4.0627 - g_loss: 8.4520\n",
      "Epoch 25/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.7273 - g_loss: 8.3934\n",
      "Epoch 26/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -4.0619 - g_loss: 8.9014\n",
      "Epoch 27/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -4.2847 - g_loss: 9.1687\n",
      "Epoch 28/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: -3.6340 - g_loss: 8.8163\n",
      "Epoch 29/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -3.3915 - g_loss: 8.2078\n",
      "Epoch 30/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - d_loss: -4.1300 - g_loss: 9.3825\n",
      "Epoch 31/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: -4.0538 - g_loss: 8.9513\n",
      "Epoch 32/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: -2.7153 - g_loss: 8.2321\n",
      "Epoch 33/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5999 - g_loss: 1.1921e-07\n",
      "Epoch 34/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - d_loss: 3.5877 - g_loss: 1.1921e-07\n",
      "Epoch 35/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5905 - g_loss: 1.1921e-07\n",
      "Epoch 36/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - d_loss: 3.5919 - g_loss: 1.1921e-07\n",
      "Epoch 37/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5939 - g_loss: 1.1921e-07\n",
      "Epoch 38/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - d_loss: 3.5696 - g_loss: 1.1921e-07\n",
      "Epoch 39/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5653 - g_loss: 1.1921e-07\n",
      "Epoch 40/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - d_loss: 3.5923 - g_loss: 1.1921e-07\n",
      "Epoch 41/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5834 - g_loss: 1.1921e-07\n",
      "Epoch 42/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5836 - g_loss: 1.1921e-07\n",
      "Epoch 43/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5972 - g_loss: 1.1921e-07\n",
      "Epoch 44/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5861 - g_loss: 1.1921e-07\n",
      "Epoch 45/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.6036 - g_loss: 1.1921e-07\n",
      "Epoch 46/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.6052 - g_loss: 1.1921e-07\n",
      "Epoch 47/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5601 - g_loss: 1.1921e-07\n",
      "Epoch 48/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.6154 - g_loss: 1.1921e-07\n",
      "Epoch 49/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5586 - g_loss: 1.1921e-07\n",
      "Epoch 50/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5958 - g_loss: 1.1921e-07\n",
      "Epoch 51/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - d_loss: 3.5712 - g_loss: 1.1921e-07\n",
      "Epoch 52/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - d_loss: 3.5906 - g_loss: 1.1921e-07\n",
      "Epoch 53/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - d_loss: 3.5996 - g_loss: 1.1921e-07\n",
      "Epoch 54/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.6027 - g_loss: 1.1921e-07\n",
      "Epoch 55/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5899 - g_loss: 1.1921e-07\n",
      "Epoch 56/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5902 - g_loss: 1.1921e-07\n",
      "Epoch 57/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.6132 - g_loss: 1.1921e-07\n",
      "Epoch 58/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5847 - g_loss: 1.1921e-07\n",
      "Epoch 59/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5763 - g_loss: 1.1921e-07\n",
      "Epoch 60/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.6007 - g_loss: 1.1921e-07\n",
      "Epoch 61/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5838 - g_loss: 1.1921e-07\n",
      "Epoch 62/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - d_loss: 3.5954 - g_loss: 1.1921e-07\n",
      "Epoch 63/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - d_loss: 3.5995 - g_loss: 1.1921e-07\n",
      "Epoch 64/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - d_loss: 3.5749 - g_loss: 1.1921e-07\n",
      "Epoch 65/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.5855 - g_loss: 1.1921e-07\n",
      "Epoch 66/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.6088 - g_loss: 1.1921e-07\n",
      "Epoch 67/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - d_loss: 3.5549 - g_loss: 1.1921e-07\n",
      "Epoch 68/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: 3.5785 - g_loss: 1.1921e-07\n",
      "Epoch 69/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.6116 - g_loss: 1.1921e-07\n",
      "Epoch 70/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5752 - g_loss: 1.1921e-07\n",
      "Epoch 71/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5859 - g_loss: 1.1921e-07\n",
      "Epoch 72/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5713 - g_loss: 1.1921e-07\n",
      "Epoch 73/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5688 - g_loss: 1.1921e-07\n",
      "Epoch 74/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5556 - g_loss: 1.1921e-07\n",
      "Epoch 75/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5950 - g_loss: 1.1921e-07\n",
      "Epoch 76/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5972 - g_loss: 1.1921e-07\n",
      "Epoch 77/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.6019 - g_loss: 1.1921e-07\n",
      "Epoch 78/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.5814 - g_loss: 1.1921e-07\n",
      "Epoch 79/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: 3.5850 - g_loss: 1.1921e-07\n",
      "Epoch 80/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.5515 - g_loss: 1.1921e-07\n",
      "Epoch 81/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.6063 - g_loss: 1.1921e-07\n",
      "Epoch 82/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - d_loss: 3.5863 - g_loss: 1.1921e-07\n",
      "Epoch 83/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - d_loss: 3.6132 - g_loss: 1.1921e-07\n",
      "Epoch 84/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.6092 - g_loss: 1.1921e-07\n",
      "Epoch 85/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5684 - g_loss: 1.1921e-07\n",
      "Epoch 86/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5828 - g_loss: 1.1921e-07\n",
      "Epoch 87/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5908 - g_loss: 1.1921e-07\n",
      "Epoch 88/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5626 - g_loss: 1.1921e-07\n",
      "Epoch 89/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5986 - g_loss: 1.1921e-07\n",
      "Epoch 90/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5612 - g_loss: 1.1921e-07\n",
      "Epoch 91/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5741 - g_loss: 1.1921e-07\n",
      "Epoch 92/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.6015 - g_loss: 1.1921e-07\n",
      "Epoch 93/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: 3.5836 - g_loss: 1.1921e-07\n",
      "Epoch 94/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5775 - g_loss: 1.1921e-07\n",
      "Epoch 95/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5871 - g_loss: 1.1921e-07\n",
      "Epoch 96/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.6025 - g_loss: 1.1921e-07\n",
      "Epoch 97/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.6130 - g_loss: 1.1921e-07\n",
      "Epoch 98/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5814 - g_loss: 1.1921e-07\n",
      "Epoch 99/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: 3.6113 - g_loss: 1.1921e-07\n",
      "Epoch 100/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: 3.5676 - g_loss: 1.1921e-07\n",
      "Epoch 101/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.5833 - g_loss: 1.1921e-07\n",
      "Epoch 102/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - d_loss: 3.5835 - g_loss: 1.1921e-07\n",
      "Epoch 103/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5675 - g_loss: 1.1921e-07\n",
      "Epoch 104/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5797 - g_loss: 1.1921e-07\n",
      "Epoch 105/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5822 - g_loss: 1.1921e-07\n",
      "Epoch 106/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.6014 - g_loss: 1.1921e-07\n",
      "Epoch 107/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.5699 - g_loss: 1.1921e-07\n",
      "Epoch 108/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 57ms/step - d_loss: 3.5645 - g_loss: 1.1921e-07\n",
      "Epoch 109/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - d_loss: 3.5850 - g_loss: 1.1921e-07\n",
      "Epoch 110/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - d_loss: 3.5879 - g_loss: 1.1921e-07\n",
      "Epoch 111/300\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - d_loss: 3.6040 - g_loss: 1.1921e-07\n",
      "Epoch 112/300\n",
      "\u001b[1m106/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - d_loss: 3.5754 - g_loss: 1.1921e-07"
     ]
    }
   ],
   "source": [
    "class DCGAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.loss_function = keras.losses.BinaryCrossentropy()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            real_predictions = self.discriminator(real_images, training=True)\n",
    "            fake_predictions = self.discriminator(generated_images, training=True)\n",
    "            real_labels = tf.ones_like(real_predictions)\n",
    "            # 생성자가 단순히 특정 패턴만 반복하지 않고 다양한 출력을 만들어내게 함\n",
    "            real_nosiy_labels = real_labels + 0.1 + tf.random.uniform(tf.shape(real_predictions))\n",
    "            fake_lables = tf.zeros_like(fake_predictions)\n",
    "            fake_noisy_labels = fake_lables - 0.1 * tf.random.uniform(tf.shape(fake_predictions))\n",
    "\n",
    "            d_real_loss = self.loss_function(real_nosiy_labels, real_predictions)\n",
    "            d_fake_loss = self.loss_function(fake_noisy_labels, fake_predictions)\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
    "\n",
    "            g_loss = self.loss_function(real_labels, fake_predictions)\n",
    "        \n",
    "        gradients_discriminator = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        gradients_generator = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "\n",
    "        self.d_optimizer.apply_gradients(zip(gradients_discriminator, self.discriminator.trainable_variables))\n",
    "        self.g_optimizer.apply_gradients(zip(gradients_generator, self.generator.trainable_variables))\n",
    "        \n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "dcgan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=100)\n",
    "dcgan.compile(d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.4, beta_2=0.999),\n",
    "              g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.4, beta_2=0.999))\n",
    "\n",
    "dcgan.fit(train, epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_width, grid_height = (10, 3)\n",
    "z_sample = np.random.normal(size=(grid_width * grid_height, 100))\n",
    "reconstructions = generator.predict(z_sample)\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(grid_width * grid_height):\n",
    "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
