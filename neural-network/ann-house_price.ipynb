{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ9PmT_1hL8n"
      },
      "source": [
        "# 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sgKh_jtiecH"
      },
      "source": [
        "## 1. Python 패키지 Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie2L7Xl4iHYp"
      },
      "source": [
        "`numpy`와 `pyplot`을 사용하기 위해 패키지를 import 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w19Lcx6LhM2V"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynk563M4ijfq"
      },
      "source": [
        "## 2. 데이터 읽고 전처리하기\n",
        "1단계: pandas로 파일 읽기  \n",
        "2단계: 데이터 정제  \n",
        "    \n",
        "    방법  \n",
        "* 데이터가 온전한지 체크하기  \n",
        "* 수치형 데이터는 정규화 해주기\n",
        "* 데이터 범주형 데이터가 있다면 숫자로 표현하기  \n",
        "* 학습데이터 나누기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파일 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"../BasicML/regression/data/house_price-train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 정제하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  데이터가 온전한지 체크하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "불필요한 ID 컬럼 날리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GdPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "...          ...      ...          ...      ...    ...   ...      ...   \n",
              "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
              "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
              "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
              "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
              "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
              "0            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
              "1            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
              "2            Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
              "3            Lvl    AllPub    Corner  ...        0    NaN    NaN         NaN   \n",
              "4            Lvl    AllPub       FR2  ...        0    NaN    NaN         NaN   \n",
              "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
              "1455         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
              "1456         Lvl    AllPub    Inside  ...        0    NaN  MnPrv         NaN   \n",
              "1457         Lvl    AllPub    Inside  ...        0    NaN  GdPrv        Shed   \n",
              "1458         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
              "1459         Lvl    AllPub    Inside  ...        0    NaN    NaN         NaN   \n",
              "\n",
              "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0          0      2    2008        WD         Normal     208500  \n",
              "1          0      5    2007        WD         Normal     181500  \n",
              "2          0      9    2008        WD         Normal     223500  \n",
              "3          0      2    2006        WD        Abnorml     140000  \n",
              "4          0     12    2008        WD         Normal     250000  \n",
              "...      ...    ...     ...       ...            ...        ...  \n",
              "1455       0      8    2007        WD         Normal     175000  \n",
              "1456       0      2    2010        WD         Normal     210000  \n",
              "1457    2500      5    2010        WD         Normal     266500  \n",
              "1458       0      4    2010        WD         Normal     142125  \n",
              "1459       0      6    2008        WD         Normal     147500  \n",
              "\n",
              "[1460 rows x 80 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.drop([\"Id\"], axis=1, inplace=True)\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "빠진 데이터가 있는지 체크"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GarageYrBlt      81\n",
            "MasVnrArea        8\n",
            "MSSubClass        0\n",
            "OpenPorchSF       0\n",
            "KitchenAbvGr      0\n",
            "TotRmsAbvGrd      0\n",
            "Fireplaces        0\n",
            "GarageCars        0\n",
            "GarageArea        0\n",
            "WoodDeckSF        0\n",
            "EnclosedPorch     0\n",
            "HalfBath          0\n",
            "3SsnPorch         0\n",
            "ScreenPorch       0\n",
            "PoolArea          0\n",
            "MiscVal           0\n",
            "MoSold            0\n",
            "YrSold            0\n",
            "BedroomAbvGr      0\n",
            "FullBath          0\n",
            "LotFrontage       0\n",
            "BsmtFinSF2        0\n",
            "LotArea           0\n",
            "OverallQual       0\n",
            "OverallCond       0\n",
            "YearBuilt         0\n",
            "YearRemodAdd      0\n",
            "BsmtFinSF1        0\n",
            "BsmtUnfSF         0\n",
            "BsmtHalfBath      0\n",
            "TotalBsmtSF       0\n",
            "1stFlrSF          0\n",
            "2ndFlrSF          0\n",
            "LowQualFinSF      0\n",
            "GrLivArea         0\n",
            "BsmtFullBath      0\n",
            "SalePrice         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "missing_values = data.select_dtypes('number').isnull().sum().sort_values(ascending=False)\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "값이 비어있는 데이터를 가지고 있는 숫자형 컬럼들 뽑기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
            "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
            "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
            "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
            "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
            "       'MoSold', 'YrSold', 'SalePrice'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "missing_values_columns = data.select_dtypes('number').isnull().columns\n",
        "print(missing_values_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "값이 비어있는 컬럼을 없애버리거나"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>...</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>...</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>...</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Edwards</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
              "0             60       RL     8450   Pave      Reg         Lvl    AllPub   \n",
              "1             20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
              "2             60       RL    11250   Pave      IR1         Lvl    AllPub   \n",
              "3             70       RL     9550   Pave      IR1         Lvl    AllPub   \n",
              "4             60       RL    14260   Pave      IR1         Lvl    AllPub   \n",
              "...          ...      ...      ...    ...      ...         ...       ...   \n",
              "1455          60       RL     7917   Pave      Reg         Lvl    AllPub   \n",
              "1456          20       RL    13175   Pave      Reg         Lvl    AllPub   \n",
              "1457          70       RL     9042   Pave      Reg         Lvl    AllPub   \n",
              "1458          20       RL     9717   Pave      Reg         Lvl    AllPub   \n",
              "1459          20       RL     9937   Pave      Reg         Lvl    AllPub   \n",
              "\n",
              "     LotConfig LandSlope Neighborhood  ... EnclosedPorch 3SsnPorch  \\\n",
              "0       Inside       Gtl      CollgCr  ...             0         0   \n",
              "1          FR2       Gtl      Veenker  ...             0         0   \n",
              "2       Inside       Gtl      CollgCr  ...             0         0   \n",
              "3       Corner       Gtl      Crawfor  ...           272         0   \n",
              "4          FR2       Gtl      NoRidge  ...             0         0   \n",
              "...        ...       ...          ...  ...           ...       ...   \n",
              "1455    Inside       Gtl      Gilbert  ...             0         0   \n",
              "1456    Inside       Gtl       NWAmes  ...             0         0   \n",
              "1457    Inside       Gtl      Crawfor  ...             0         0   \n",
              "1458    Inside       Gtl        NAmes  ...           112         0   \n",
              "1459    Inside       Gtl      Edwards  ...             0         0   \n",
              "\n",
              "     ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \\\n",
              "0              0        0        0       2    2008        WD        Normal   \n",
              "1              0        0        0       5    2007        WD        Normal   \n",
              "2              0        0        0       9    2008        WD        Normal   \n",
              "3              0        0        0       2    2006        WD       Abnorml   \n",
              "4              0        0        0      12    2008        WD        Normal   \n",
              "...          ...      ...      ...     ...     ...       ...           ...   \n",
              "1455           0        0        0       8    2007        WD        Normal   \n",
              "1456           0        0        0       2    2010        WD        Normal   \n",
              "1457           0        0     2500       5    2010        WD        Normal   \n",
              "1458           0        0        0       4    2010        WD        Normal   \n",
              "1459           0        0        0       6    2008        WD        Normal   \n",
              "\n",
              "     SalePrice  \n",
              "0       208500  \n",
              "1       181500  \n",
              "2       223500  \n",
              "3       140000  \n",
              "4       250000  \n",
              "...        ...  \n",
              "1455    175000  \n",
              "1456    210000  \n",
              "1457    266500  \n",
              "1458    142125  \n",
              "1459    147500  \n",
              "\n",
              "[1460 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSSubClass      0\n",
            "CentralAir      0\n",
            "2ndFlrSF        0\n",
            "LowQualFinSF    0\n",
            "GrLivArea       0\n",
            "               ..\n",
            "BsmtFinSF1      0\n",
            "BsmtFinSF2      0\n",
            "BsmtUnfSF       0\n",
            "TotalBsmtSF     0\n",
            "SalePrice       0\n",
            "Length: 61, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data.drop(missing_values_columns, axis=1, inplace=True)\n",
        "display(data)\n",
        "missing_values = data.isnull().sum().sort_values(ascending=False)\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "채워넣기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in missing_values_columns:\n",
        "     data[col] = data[col].fillna(data.loc[:, col].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  데이터 정규화 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.033420</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.50</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.241078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.202055</td>\n",
              "      <td>0.038795</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.25</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.203583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.160959</td>\n",
              "      <td>0.046507</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.50</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.261908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.133562</td>\n",
              "      <td>0.038561</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>0.145952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.215753</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.298709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.140411</td>\n",
              "      <td>0.030929</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.25</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.194556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.219178</td>\n",
              "      <td>0.055505</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.243161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.154110</td>\n",
              "      <td>0.036187</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GdPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>0.16129</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.321622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.160959</td>\n",
              "      <td>0.039342</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.148903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>RL</td>\n",
              "      <td>0.184932</td>\n",
              "      <td>0.040370</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.50</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0.156367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MSSubClass MSZoning  LotFrontage   LotArea Street Alley LotShape  \\\n",
              "0       0.235294       RL     0.150685  0.033420   Pave   NaN      Reg   \n",
              "1       0.000000       RL     0.202055  0.038795   Pave   NaN      Reg   \n",
              "2       0.235294       RL     0.160959  0.046507   Pave   NaN      IR1   \n",
              "3       0.294118       RL     0.133562  0.038561   Pave   NaN      IR1   \n",
              "4       0.235294       RL     0.215753  0.060576   Pave   NaN      IR1   \n",
              "...          ...      ...          ...       ...    ...   ...      ...   \n",
              "1455    0.235294       RL     0.140411  0.030929   Pave   NaN      Reg   \n",
              "1456    0.000000       RL     0.219178  0.055505   Pave   NaN      Reg   \n",
              "1457    0.294118       RL     0.154110  0.036187   Pave   NaN      Reg   \n",
              "1458    0.000000       RL     0.160959  0.039342   Pave   NaN      Reg   \n",
              "1459    0.000000       RL     0.184932  0.040370   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
              "0            Lvl    AllPub    Inside  ...      0.0    NaN    NaN         NaN   \n",
              "1            Lvl    AllPub       FR2  ...      0.0    NaN    NaN         NaN   \n",
              "2            Lvl    AllPub    Inside  ...      0.0    NaN    NaN         NaN   \n",
              "3            Lvl    AllPub    Corner  ...      0.0    NaN    NaN         NaN   \n",
              "4            Lvl    AllPub       FR2  ...      0.0    NaN    NaN         NaN   \n",
              "...          ...       ...       ...  ...      ...    ...    ...         ...   \n",
              "1455         Lvl    AllPub    Inside  ...      0.0    NaN    NaN         NaN   \n",
              "1456         Lvl    AllPub    Inside  ...      0.0    NaN  MnPrv         NaN   \n",
              "1457         Lvl    AllPub    Inside  ...      0.0    NaN  GdPrv        Shed   \n",
              "1458         Lvl    AllPub    Inside  ...      0.0    NaN    NaN         NaN   \n",
              "1459         Lvl    AllPub    Inside  ...      0.0    NaN    NaN         NaN   \n",
              "\n",
              "      MiscVal    MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0     0.00000  0.090909    0.50        WD         Normal   0.241078  \n",
              "1     0.00000  0.363636    0.25        WD         Normal   0.203583  \n",
              "2     0.00000  0.727273    0.50        WD         Normal   0.261908  \n",
              "3     0.00000  0.090909    0.00        WD        Abnorml   0.145952  \n",
              "4     0.00000  1.000000    0.50        WD         Normal   0.298709  \n",
              "...       ...       ...     ...       ...            ...        ...  \n",
              "1455  0.00000  0.636364    0.25        WD         Normal   0.194556  \n",
              "1456  0.00000  0.090909    1.00        WD         Normal   0.243161  \n",
              "1457  0.16129  0.363636    1.00        WD         Normal   0.321622  \n",
              "1458  0.00000  0.272727    1.00        WD         Normal   0.148903  \n",
              "1459  0.00000  0.454545    0.50        WD         Normal   0.156367  \n",
              "\n",
              "[1460 rows x 80 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "numeric_columns = data.select_dtypes('number').columns\n",
        "data[numeric_columns] = min_max_scaler.fit_transform(data[numeric_columns])\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  데이터 범주형 데이터가 있다면 숫자로 표현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>3</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.033420</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.50</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.241078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.202055</td>\n",
              "      <td>0.038795</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.25</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.203583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>3</td>\n",
              "      <td>0.160959</td>\n",
              "      <td>0.046507</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.50</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.261908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>3</td>\n",
              "      <td>0.133562</td>\n",
              "      <td>0.038561</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.145952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>3</td>\n",
              "      <td>0.215753</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.298709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>3</td>\n",
              "      <td>0.140411</td>\n",
              "      <td>0.030929</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.25</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.194556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.219178</td>\n",
              "      <td>0.055505</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>1.00</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.243161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>3</td>\n",
              "      <td>0.154110</td>\n",
              "      <td>0.036187</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.16129</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>1.00</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.321622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.160959</td>\n",
              "      <td>0.039342</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>1.00</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.148903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.184932</td>\n",
              "      <td>0.040370</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.50</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.156367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MSSubClass  MSZoning  LotFrontage   LotArea  Street  Alley  LotShape  \\\n",
              "0       0.235294         3     0.150685  0.033420       1      2         3   \n",
              "1       0.000000         3     0.202055  0.038795       1      2         3   \n",
              "2       0.235294         3     0.160959  0.046507       1      2         0   \n",
              "3       0.294118         3     0.133562  0.038561       1      2         0   \n",
              "4       0.235294         3     0.215753  0.060576       1      2         0   \n",
              "...          ...       ...          ...       ...     ...    ...       ...   \n",
              "1455    0.235294         3     0.140411  0.030929       1      2         3   \n",
              "1456    0.000000         3     0.219178  0.055505       1      2         3   \n",
              "1457    0.294118         3     0.154110  0.036187       1      2         3   \n",
              "1458    0.000000         3     0.160959  0.039342       1      2         3   \n",
              "1459    0.000000         3     0.184932  0.040370       1      2         3   \n",
              "\n",
              "      LandContour  Utilities  LotConfig  ...  PoolArea  PoolQC  Fence  \\\n",
              "0               3          0          4  ...       0.0       3      4   \n",
              "1               3          0          2  ...       0.0       3      4   \n",
              "2               3          0          4  ...       0.0       3      4   \n",
              "3               3          0          0  ...       0.0       3      4   \n",
              "4               3          0          2  ...       0.0       3      4   \n",
              "...           ...        ...        ...  ...       ...     ...    ...   \n",
              "1455            3          0          4  ...       0.0       3      4   \n",
              "1456            3          0          4  ...       0.0       3      2   \n",
              "1457            3          0          4  ...       0.0       3      0   \n",
              "1458            3          0          4  ...       0.0       3      4   \n",
              "1459            3          0          4  ...       0.0       3      4   \n",
              "\n",
              "      MiscFeature  MiscVal    MoSold  YrSold  SaleType  SaleCondition  \\\n",
              "0               4  0.00000  0.090909    0.50         8              4   \n",
              "1               4  0.00000  0.363636    0.25         8              4   \n",
              "2               4  0.00000  0.727273    0.50         8              4   \n",
              "3               4  0.00000  0.090909    0.00         8              0   \n",
              "4               4  0.00000  1.000000    0.50         8              4   \n",
              "...           ...      ...       ...     ...       ...            ...   \n",
              "1455            4  0.00000  0.636364    0.25         8              4   \n",
              "1456            4  0.00000  0.090909    1.00         8              4   \n",
              "1457            2  0.16129  0.363636    1.00         8              4   \n",
              "1458            4  0.00000  0.272727    1.00         8              4   \n",
              "1459            4  0.00000  0.454545    0.50         8              4   \n",
              "\n",
              "      SalePrice  \n",
              "0      0.241078  \n",
              "1      0.203583  \n",
              "2      0.261908  \n",
              "3      0.145952  \n",
              "4      0.298709  \n",
              "...         ...  \n",
              "1455   0.194556  \n",
              "1456   0.243161  \n",
              "1457   0.321622  \n",
              "1458   0.148903  \n",
              "1459   0.156367  \n",
              "\n",
              "[1460 rows x 80 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "non_numeric_columns = data.select_dtypes(exclude='number').columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for i in non_numeric_columns:\n",
        "    data[i] = label_encoder.fit_transform(data[i])\n",
        "\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  학습데이터와 검증데이터로 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "numeric_data = data[numeric_columns]\n",
        "\n",
        "X = numeric_data.loc[:, numeric_data.columns != 'SalePrice']\n",
        "Y = numeric_data.loc[:, numeric_data.columns == 'SalePrice']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 모델 만들고 학습 및 검증하기\n",
        "## 1. 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 512)               18944     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,441\n",
            "Trainable params: 109,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential # keras의 Sequential()을 임포트\n",
        "from tensorflow.keras.layers import Dense, Dropout # keras의 Dense()를 임포트\n",
        "from tensorflow.keras import optimizers # keras의 옵티마이저를 임포트\n",
        "\n",
        "# Sequential()로 model이라는 이름의 모델 객체을 만듭니다.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(512, input_dim=len(numeric_data.columns) - 1, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# 모델 모양 확인\n",
        "model.summary()\n",
        "\n",
        "# optimer로는 adam, lr=0.5\n",
        "adam = optimizers.Adam(learning_rate=0.3)\n",
        "\n",
        "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
        "model.compile(optimizer=adam, loss='mse', metrics=['mse'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 19ms/step - loss: 2420515584.0000 - mse: 2420515584.0000 - val_loss: 53.8596 - val_mse: 53.8596\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 22.5262 - mse: 22.5262 - val_loss: 8.1885 - val_mse: 8.1885\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 5.5929 - mse: 5.5929 - val_loss: 4.7000 - val_mse: 4.7000\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.4363 - mse: 1.4363 - val_loss: 0.0452 - val_mse: 0.0452\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.2474 - mse: 0.2474 - val_loss: 0.1832 - val_mse: 0.1832\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0732 - mse: 0.0732 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0461 - val_mse: 0.0461\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.8345 - mse: 5.8345 - val_loss: 15.9718 - val_mse: 15.9718\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4.3384 - mse: 4.3384 - val_loss: 2.4145 - val_mse: 2.4145\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.0248 - mse: 1.0248 - val_loss: 0.1628 - val_mse: 0.1628\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3233 - mse: 0.3233 - val_loss: 0.2643 - val_mse: 0.2643\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0859 - mse: 0.0859 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.6268 - val_mse: 0.6268\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 17.2460 - mse: 17.2460 - val_loss: 0.5159 - val_mse: 0.5159\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4.0585 - mse: 4.0585 - val_loss: 2.3042 - val_mse: 2.3042\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8368 - mse: 0.8368 - val_loss: 0.3731 - val_mse: 0.3731\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1652 - mse: 0.1652 - val_loss: 0.0534 - val_mse: 0.0534\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.1022 - val_mse: 0.1022\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0642 - val_mse: 0.0642\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0680 - mse: 0.0680 - val_loss: 0.0829 - val_mse: 0.0829\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1256 - mse: 0.1256 - val_loss: 0.6782 - val_mse: 0.6782\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 8.1470 - mse: 8.1470 - val_loss: 1.8301 - val_mse: 1.8301\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.6210 - mse: 2.6210 - val_loss: 2.2921 - val_mse: 2.2921\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6557 - mse: 0.6557 - val_loss: 0.0550 - val_mse: 0.0550\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.2074 - mse: 0.2074 - val_loss: 0.1472 - val_mse: 0.1472\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2465 - mse: 0.2465 - val_loss: 0.3771 - val_mse: 0.3771\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2318 - mse: 0.2318 - val_loss: 0.6844 - val_mse: 0.6844\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.2567 - mse: 7.2567 - val_loss: 7.6288 - val_mse: 7.6288\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.5743 - mse: 2.5743 - val_loss: 0.8407 - val_mse: 0.8407\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.6109 - mse: 0.6109 - val_loss: 0.2135 - val_mse: 0.2135\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5940 - mse: 0.5940 - val_loss: 0.3949 - val_mse: 0.3949\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3043 - mse: 0.3043 - val_loss: 0.1037 - val_mse: 0.1037\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1553 - mse: 0.1553 - val_loss: 0.5360 - val_mse: 0.5360\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.3439 - mse: 7.3439 - val_loss: 0.9314 - val_mse: 0.9314\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.2355 - mse: 2.2355 - val_loss: 2.3492 - val_mse: 2.3492\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.8183 - mse: 0.8183 - val_loss: 0.7103 - val_mse: 0.7103\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2590 - mse: 0.2590 - val_loss: 0.0711 - val_mse: 0.0711\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1319 - mse: 0.1319 - val_loss: 0.2881 - val_mse: 0.2881\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.8320 - mse: 0.8320 - val_loss: 1.5852 - val_mse: 1.5852\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 10.7819 - mse: 10.7819 - val_loss: 2.9084 - val_mse: 2.9084\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3.4942 - mse: 3.4942 - val_loss: 1.3361 - val_mse: 1.3361\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4946 - mse: 0.4946 - val_loss: 0.0795 - val_mse: 0.0795\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0178 - val_mse: 0.0178\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0955 - mse: 0.0955 - val_loss: 0.2797 - val_mse: 0.2797\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.8079 - mse: 1.8079 - val_loss: 3.3296 - val_mse: 3.3296\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.5997 - mse: 2.5997 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7506 - mse: 0.7506 - val_loss: 1.9984 - val_mse: 1.9984\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.5956 - mse: 3.5956 - val_loss: 0.5745 - val_mse: 0.5745\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1423 - mse: 0.1423 - val_loss: 0.0646 - val_mse: 0.0646\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7989 - mse: 0.7989 - val_loss: 5.3682 - val_mse: 5.3682\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9.9646 - mse: 9.9646 - val_loss: 4.2335 - val_mse: 4.2335\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6210 - mse: 1.6210 - val_loss: 0.4076 - val_mse: 0.4076\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.4264 - mse: 0.4264 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0599 - val_mse: 0.0599\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.5210 - val_mse: 0.5210\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7.4409 - mse: 7.4409 - val_loss: 6.5874 - val_mse: 6.5874\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.5421 - mse: 2.5421 - val_loss: 3.8222 - val_mse: 3.8222\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3642 - mse: 1.3642 - val_loss: 1.6517 - val_mse: 1.6517\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.0024 - mse: 1.0024 - val_loss: 0.0940 - val_mse: 0.0940\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0835 - mse: 0.0835 - val_loss: 0.1971 - val_mse: 0.1971\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3334 - mse: 0.3334 - val_loss: 0.0762 - val_mse: 0.0762\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.9843 - mse: 0.9843 - val_loss: 0.6334 - val_mse: 0.6334\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.8393 - mse: 2.8393 - val_loss: 9.1290 - val_mse: 9.1290\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.7126 - mse: 3.7126 - val_loss: 0.7295 - val_mse: 0.7295\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7139 - mse: 0.7139 - val_loss: 0.2427 - val_mse: 0.2427\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3542 - mse: 0.3542 - val_loss: 0.9761 - val_mse: 0.9761\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5825 - mse: 0.5825 - val_loss: 0.6258 - val_mse: 0.6258\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1163 - mse: 0.1163 - val_loss: 0.0890 - val_mse: 0.0890\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.1738 - val_mse: 0.1738\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 9.4719 - mse: 9.4719 - val_loss: 36.5624 - val_mse: 36.5624\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 9.4800 - mse: 9.4800 - val_loss: 0.2290 - val_mse: 0.2290\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1622 - mse: 1.1622 - val_loss: 0.1666 - val_mse: 0.1666\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.2347 - mse: 0.2347 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0870 - mse: 0.0870 - val_loss: 0.0312 - val_mse: 0.0312\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.1748 - val_mse: 0.1748\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.2831 - mse: 0.2831 - val_loss: 0.3937 - val_mse: 0.3937\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2413 - mse: 0.2413 - val_loss: 0.1919 - val_mse: 0.1919\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2353 - mse: 0.2353 - val_loss: 0.2357 - val_mse: 0.2357\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2720 - mse: 0.2720 - val_loss: 0.4023 - val_mse: 0.4023\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3132 - mse: 0.3132 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5891 - mse: 0.5891 - val_loss: 2.4201 - val_mse: 2.4201\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8.6674 - mse: 8.6674 - val_loss: 2.4774 - val_mse: 2.4774\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.0397 - mse: 2.0397 - val_loss: 1.2050 - val_mse: 1.2050\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.5247 - mse: 0.5247 - val_loss: 0.4835 - val_mse: 0.4835\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0821 - mse: 0.0821 - val_loss: 0.5920 - val_mse: 0.5920\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1549 - mse: 0.1549 - val_loss: 0.0493 - val_mse: 0.0493\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.3037 - mse: 0.3037 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1829 - mse: 0.1829 - val_loss: 0.5413 - val_mse: 0.5413\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.2730 - mse: 1.2730 - val_loss: 3.8142 - val_mse: 3.8142\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.4196 - mse: 3.4196 - val_loss: 0.1082 - val_mse: 0.1082\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.2095 - mse: 0.2095 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3971 - mse: 0.3971 - val_loss: 0.9217 - val_mse: 0.9217\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.5966 - mse: 0.5966 - val_loss: 0.5142 - val_mse: 0.5142\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.9519 - mse: 0.9519 - val_loss: 1.8120 - val_mse: 1.8120\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 5.9657 - mse: 5.9657 - val_loss: 1.0866 - val_mse: 1.0866\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5386 - mse: 0.5386 - val_loss: 0.0722 - val_mse: 0.0722\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0275 - val_mse: 0.0275\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1122 - mse: 0.1122 - val_loss: 0.0450 - val_mse: 0.0450\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0733 - val_mse: 0.0733\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3047 - mse: 0.3047 - val_loss: 1.0637 - val_mse: 1.0637\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 7.2415 - mse: 7.2415 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.8166 - mse: 1.8166 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.5200 - mse: 0.5200 - val_loss: 0.0993 - val_mse: 0.0993\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1584 - mse: 0.1584 - val_loss: 0.3388 - val_mse: 0.3388\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1772 - mse: 0.1772 - val_loss: 0.1214 - val_mse: 0.1214\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.2114 - val_mse: 0.2114\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1650 - mse: 0.1650 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.1867 - val_mse: 0.1867\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7120 - mse: 0.7120 - val_loss: 3.8189 - val_mse: 3.8189\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4.6642 - mse: 4.6642 - val_loss: 1.2664 - val_mse: 1.2664\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.7107 - mse: 0.7107 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1745 - mse: 0.1745 - val_loss: 0.1525 - val_mse: 0.1525\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2858 - mse: 0.2858 - val_loss: 0.0745 - val_mse: 0.0745\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2116 - mse: 0.2116 - val_loss: 0.1898 - val_mse: 0.1898\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2.3087 - mse: 2.3087 - val_loss: 8.1850 - val_mse: 8.1850\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3.9141 - mse: 3.9141 - val_loss: 0.7276 - val_mse: 0.7276\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6918 - mse: 0.6918 - val_loss: 0.6804 - val_mse: 0.6804\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.2425 - mse: 0.2425 - val_loss: 0.0829 - val_mse: 0.0829\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1418 - mse: 0.1418 - val_loss: 0.3612 - val_mse: 0.3612\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1545 - mse: 0.1545 - val_loss: 0.0271 - val_mse: 0.0271\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0572 - val_mse: 0.0572\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0931 - mse: 0.0931 - val_loss: 0.3922 - val_mse: 0.3922\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.6609 - mse: 1.6609 - val_loss: 11.3851 - val_mse: 11.3851\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 7.1318 - mse: 7.1318 - val_loss: 0.3270 - val_mse: 0.3270\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.4982 - val_mse: 0.4982\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3042 - mse: 0.3042 - val_loss: 0.4763 - val_mse: 0.4763\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 0.0821 - val_mse: 0.0821\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1684 - mse: 0.1684 - val_loss: 0.5014 - val_mse: 0.5014\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3093 - mse: 0.3093 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.1987 - mse: 0.1987 - val_loss: 0.3423 - val_mse: 0.3423\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3396 - mse: 0.3396 - val_loss: 0.3430 - val_mse: 0.3430\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.2248 - mse: 0.2248 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.7653 - mse: 0.7653 - val_loss: 0.8407 - val_mse: 0.8407\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.4490 - mse: 0.4490 - val_loss: 1.3550 - val_mse: 1.3550\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2.4645 - mse: 2.4645 - val_loss: 4.1917 - val_mse: 4.1917\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7999 - mse: 1.7999 - val_loss: 0.9650 - val_mse: 0.9650\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.2769 - mse: 0.2769 - val_loss: 0.2333 - val_mse: 0.2333\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3776 - mse: 0.3776 - val_loss: 0.4742 - val_mse: 0.4742\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.3418 - mse: 0.3418 - val_loss: 0.3656 - val_mse: 0.3656\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7267 - mse: 0.7267 - val_loss: 0.2892 - val_mse: 0.2892\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.7981 - mse: 0.7981 - val_loss: 4.1425 - val_mse: 4.1425\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 1.7628 - mse: 1.7628 - val_loss: 0.4091 - val_mse: 0.4091\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3978 - mse: 0.3978 - val_loss: 0.1499 - val_mse: 0.1499\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.5031 - mse: 0.5031 - val_loss: 0.0526 - val_mse: 0.0526\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1949 - mse: 0.1949 - val_loss: 0.0817 - val_mse: 0.0817\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.9021 - mse: 0.9021 - val_loss: 2.2366 - val_mse: 2.2366\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.9535 - mse: 0.9535 - val_loss: 0.4245 - val_mse: 0.4245\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.1604 - val_mse: 0.1604\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.8121 - mse: 0.8121 - val_loss: 0.4957 - val_mse: 0.4957\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.7588 - mse: 1.7588 - val_loss: 4.2034 - val_mse: 4.2034\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 1.0130 - mse: 1.0130 - val_loss: 0.0479 - val_mse: 0.0479\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0192 - val_mse: 0.0192\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0373 - val_mse: 0.0373\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0375 - mse: 0.0375 - val_loss: 0.1365 - val_mse: 0.1365\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 2.0735 - mse: 2.0735 - val_loss: 11.5744 - val_mse: 11.5744\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 5.5137 - mse: 5.5137 - val_loss: 1.0770 - val_mse: 1.0770\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.7592 - mse: 0.7592 - val_loss: 0.2016 - val_mse: 0.2016\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.0446 - val_mse: 0.0446\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0236 - val_mse: 0.0236\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.1868 - mse: 0.1868 - val_loss: 0.0204 - val_mse: 0.0204\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 0.0851 - val_mse: 0.0851\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0880 - mse: 0.0880 - val_loss: 0.1720 - val_mse: 0.1720\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0821 - mse: 0.0821 - val_loss: 0.0293 - val_mse: 0.0293\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.1772 - mse: 0.1772 - val_loss: 0.0449 - val_mse: 0.0449\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.6168 - mse: 0.6168 - val_loss: 1.7659 - val_mse: 1.7659\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 1.3303 - mse: 1.3303 - val_loss: 0.0684 - val_mse: 0.0684\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.3167 - mse: 0.3167 - val_loss: 0.7313 - val_mse: 0.7313\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.4823 - mse: 0.4823 - val_loss: 0.5472 - val_mse: 0.5472\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.3486 - mse: 0.3486 - val_loss: 1.3906 - val_mse: 1.3906\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.9915 - mse: 0.9915 - val_loss: 0.2019 - val_mse: 0.2019\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.4392 - mse: 0.4392 - val_loss: 0.0800 - val_mse: 0.0800\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0828 - mse: 0.0828 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 1.8093 - mse: 1.8093 - val_loss: 1.1520 - val_mse: 1.1520\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 1.0095 - mse: 1.0095 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.4007 - mse: 0.4007 - val_loss: 0.4518 - val_mse: 0.4518\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.6778 - mse: 0.6778 - val_loss: 0.0576 - val_mse: 0.0576\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.2316 - mse: 0.2316 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0762 - mse: 0.0762 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3143 - mse: 0.3143 - val_loss: 0.7859 - val_mse: 0.7859\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.5095 - mse: 0.5095 - val_loss: 0.5353 - val_mse: 0.5353\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 1.3664 - mse: 1.3664 - val_loss: 0.7817 - val_mse: 0.7817\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.2839 - mse: 0.2839 - val_loss: 0.0183 - val_mse: 0.0183\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1777 - mse: 0.1777 - val_loss: 0.2997 - val_mse: 0.2997\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0847 - mse: 0.0847 - val_loss: 0.1369 - val_mse: 0.1369\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0983 - mse: 0.0983 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.4204 - mse: 0.4204 - val_loss: 1.3828 - val_mse: 1.3828\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3619 - mse: 0.3619 - val_loss: 0.1206 - val_mse: 0.1206\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1065 - mse: 0.1065 - val_loss: 0.4383 - val_mse: 0.4383\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1946 - mse: 0.1946 - val_loss: 0.2183 - val_mse: 0.2183\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0413 - val_mse: 0.0413\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0615 - val_mse: 0.0615\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0190 - val_mse: 0.0190\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0733 - val_mse: 0.0733\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0635 - mse: 0.0635 - val_loss: 0.0919 - val_mse: 0.0919\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1191 - mse: 0.1191 - val_loss: 0.0436 - val_mse: 0.0436\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0566 - mse: 0.0566 - val_loss: 0.0808 - val_mse: 0.0808\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.1605 - val_mse: 0.1605\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.5356 - mse: 0.5356 - val_loss: 0.1247 - val_mse: 0.1247\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.3257 - mse: 0.3257 - val_loss: 0.0768 - val_mse: 0.0768\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.2241 - mse: 0.2241 - val_loss: 0.0429 - val_mse: 0.0429\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.0682 - val_mse: 0.0682\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.1041 - mse: 0.1041 - val_loss: 0.1015 - val_mse: 0.1015\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0805 - mse: 0.0805 - val_loss: 0.0290 - val_mse: 0.0290\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.0553 - val_mse: 0.0553\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0885 - mse: 0.0885 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0417 - mse: 0.0417 - val_loss: 0.0673 - val_mse: 0.0673\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.1038 - val_mse: 0.1038\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0695 - val_mse: 0.0695\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3495 - mse: 0.3495 - val_loss: 0.6168 - val_mse: 0.6168\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.1306 - mse: 0.1306 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3234 - mse: 0.3234 - val_loss: 0.0439 - val_mse: 0.0439\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1589 - mse: 0.1589 - val_loss: 0.1836 - val_mse: 0.1836\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.4749 - val_mse: 0.4749\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.3889 - mse: 1.3889 - val_loss: 0.4037 - val_mse: 0.4037\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2017 - mse: 0.2017 - val_loss: 0.1492 - val_mse: 0.1492\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 0.1818 - val_mse: 0.1818\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1832 - mse: 0.1832 - val_loss: 0.0668 - val_mse: 0.0668\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 0.1900 - val_mse: 0.1900\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.1844 - mse: 0.1844 - val_loss: 0.0728 - val_mse: 0.0728\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0187 - val_mse: 0.0187\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0338 - val_mse: 0.0338\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0263 - val_mse: 0.0263\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.1077 - val_mse: 0.1077\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0836 - mse: 0.0836 - val_loss: 0.0753 - val_mse: 0.0753\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0639 - mse: 0.0639 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0659 - mse: 0.0659 - val_loss: 0.0614 - val_mse: 0.0614\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0679 - val_mse: 0.0679\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0535 - mse: 0.0535 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.1954 - mse: 0.1954 - val_loss: 0.0874 - val_mse: 0.0874\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0351 - val_mse: 0.0351\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0848 - mse: 0.0848 - val_loss: 0.0561 - val_mse: 0.0561\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0911 - val_mse: 0.0911\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0381 - val_mse: 0.0381\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0786 - mse: 0.0786 - val_loss: 0.0479 - val_mse: 0.0479\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2536 - mse: 0.2536 - val_loss: 0.0725 - val_mse: 0.0725\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0636 - mse: 0.0636 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0182 - val_mse: 0.0182\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0191 - val_mse: 0.0191\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0192 - val_mse: 0.0192\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0182 - val_mse: 0.0182\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0196 - val_mse: 0.0196\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0173 - val_mse: 0.0173\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0193 - val_mse: 0.0193\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0168 - val_mse: 0.0168\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0171 - val_mse: 0.0171\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0282 - val_mse: 0.0282\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0168 - val_mse: 0.0168\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0264 - val_mse: 0.0264\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0459 - val_mse: 0.0459\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0218 - val_mse: 0.0218\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0191 - val_mse: 0.0191\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0195 - val_mse: 0.0195\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0187 - val_mse: 0.0187\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0389 - val_mse: 0.0389\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0346 - val_mse: 0.0346\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0473 - val_mse: 0.0473\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0319 - val_mse: 0.0319\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0270 - val_mse: 0.0270\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0424 - val_mse: 0.0424\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0533 - val_mse: 0.0533\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.1024 - val_mse: 0.1024\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0741 - val_mse: 0.0741\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0520 - val_mse: 0.0520\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0359 - val_mse: 0.0359\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0171 - val_mse: 0.0171\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0879 - val_mse: 0.0879\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0522 - mse: 0.0522 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.1223 - val_mse: 0.1223\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0194 - val_mse: 0.0194\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0191 - val_mse: 0.0191\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0413 - val_mse: 0.0413\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0628 - mse: 0.0628 - val_loss: 0.1742 - val_mse: 0.1742\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 0.0899 - mse: 0.0899 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0467 - val_mse: 0.0467\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0405 - val_mse: 0.0405\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0397 - val_mse: 0.0397\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0409 - val_mse: 0.0409\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0184 - val_mse: 0.0184\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0289 - mse: 0.0289 - val_loss: 0.0286 - val_mse: 0.0286\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0303 - val_mse: 0.0303\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0483 - val_mse: 0.0483\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0189 - val_mse: 0.0189\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0867 - val_mse: 0.0867\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0387 - val_mse: 0.0387\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0669 - val_mse: 0.0669\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.1002 - val_mse: 0.1002\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0980 - val_mse: 0.0980\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0691 - mse: 0.0691 - val_loss: 0.0456 - val_mse: 0.0456\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.0825 - val_mse: 0.0825\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 1.1549 - val_mse: 1.1549\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 32.0874 - mse: 32.0874 - val_loss: 8.5488 - val_mse: 8.5488\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 24.9293 - mse: 24.9293 - val_loss: 2.2360 - val_mse: 2.2360\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.1289 - mse: 2.1289 - val_loss: 2.0148 - val_mse: 2.0148\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.9398 - mse: 1.9398 - val_loss: 1.8502 - val_mse: 1.8502\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7851 - mse: 1.7851 - val_loss: 1.7047 - val_mse: 1.7047\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1.6451 - mse: 1.6451 - val_loss: 1.5709 - val_mse: 1.5709\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1.5157 - mse: 1.5157 - val_loss: 1.4471 - val_mse: 1.4471\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.3959 - mse: 1.3959 - val_loss: 1.3320 - val_mse: 1.3320\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.2847 - mse: 1.2847 - val_loss: 1.2255 - val_mse: 1.2255\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1.1816 - mse: 1.1816 - val_loss: 1.1268 - val_mse: 1.1268\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 1.0862 - mse: 1.0862 - val_loss: 1.0354 - val_mse: 1.0354\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.9977 - mse: 0.9977 - val_loss: 0.9509 - val_mse: 0.9509\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.9161 - mse: 0.9161 - val_loss: 0.8726 - val_mse: 0.8726\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.8405 - mse: 0.8405 - val_loss: 0.8004 - val_mse: 0.8004\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9592c16a10>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 1000번 시도합니다.\n",
        "model.fit(X_train, Y_train, batch_size=64, epochs=500, shuffle=True,\n",
        "          validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 모델 검증하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0331\n",
            "[0.0330817811191082, 0.0330817811191082]\n",
            "14/14 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print(score)\n",
        "\n",
        "Y_predict = model.predict(X_test)\n",
        "plt.figure()\n",
        "plt.scatter(Y_test, Y_predict, alpha=.5, c=['r'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
